##################################################
######  Configuration Options for HYPERION #######
##################################################

#============================
# SIMULATION & INFERENCE 
#============================
detectors: ["L1", "H1", "V1"]

reference_gps_time: 1370692818 #1242442967.4 #1370692818

fs: 2048 #sampling frequency Hz for simulations & inference 

ASD_reference_run: O3_GW190521 #reference run for the ASDs

use_reference_asd: True #use the reference run for the ASDs

#inference_parameters: ["M", "q", "e0", "p_0", "distance", "polarization", "inclination", "time_shift", "ra", "dec"]
#inference_parameters: ["M", "q", "e0", "p_0", "distance", "time_shift", "ra", "dec"]

#waveform: "EffectiveFlyByTemplate"
waveform_model: "TEOBResumSDALI"

prior: "TEOBResumS_hyperbolic"

inference_parameters: ["M", "Mchirp", "q", "H_hyp", "r_hyp", "distance", "inclination", "polarization", "coalescence_angle","tcoal", "ra", "dec"]
#inference_parameters: ["M", "q", "ecc", "distance", "inclination", "polarization", "coalescence_angle", "tcoal", "ra", "dec"]

duration: 2 #duration in seconds for the simulated signals


#============================
# FLOW and EMBEDDING NETWORK
#============================
flow:
  num_coupling_layers: 10

coupling_layers:
  num_features:     3
  num_identity:     2
  num_transformed:  1

base_distribution:
  dist_name:         "MultivariateNormalBase"
  kwargs:
    dim:              3
    trainable:        false
    #num_components:   2

embedding_network:
  model:            "CNN+ResNet+Attention"
  kwargs:
    num_blocks:       5
    block_dims:       [2048, 1024, 512, 256]
    strain_out_dim:   256
    use_batch_norm:   false
    dropout_probability: 0.2

    #slicer kwargs:
    overlap : 15
    segment_len: 0.2

    #attention kwargs
    num_heads: 32
    add_bias_kv: true

    CNN_filters                   : [32, 64, 128]
    CNN_kernel_sizes              : [5, 5, 5]
    #CNN_localization_filters     : [16, 32, 16, 32, 64, 128]
    #CNN_localization_kernel_sizes: [128, 64, 32, 16, 8, 4]
    #CNN_localization_kernel_sizes: [7, 7, 5, 5, 3, 3]


#============================
# TRAINING options
#============================
training_options:
  num_epochs: 300

  batch_size: 256

  initial_learning_rate: 0.0001

  steps_per_epoch: 1000
  val_steps_per_epoch: 150

  num_preload_train: 2000
  num_preload_val: 1000

  n_proc: os.cpu_count()

  whiten_kwargs:
    method: "gwpy"
    normalize: True

  add_noise: True

  lr_schedule:
    #scheduler: CosineAnnealingLR
    #kwargs:
    #  T_max: 300 #has to be equal to num_epochs
    
    scheduler: ReduceLROnPlateau
    kwargs:
      factor:    0.5
      patience:  20
      mode:      min
      threshold: 0
    
  optimizer:
    algorithm: Adam

  seeds:
    train:   123
    val:     1234
    test:    12345

  verbose:   true

